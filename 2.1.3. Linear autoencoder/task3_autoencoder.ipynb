{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 19962), started 0:00:14 ago. (Use '!kill 19962' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ce54f540285cd1a9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ce54f540285cd1a9\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !unzip experiment.zip -d .\n",
    "# %reload_ext tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./experiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset & general parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset был скачан по ссылке https://disk.yandex.ru/d/bwUVH8hR1MRNrg.\n",
    "\n",
    "В нём предствлена выборка Twitter (эмбединги предложений)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8061 1939\n"
     ]
    }
   ],
   "source": [
    "root = 'topicmodeling'\n",
    "dataset_path = 'twitter.csv'\n",
    "\n",
    "f = open(root + '/' + dataset_path, \"r\")\n",
    "dataset = pd.read_csv(f)\n",
    "\n",
    "dataset = dataset[dataset[['tag', 'message']].notnull().all(1)]\n",
    "\n",
    "dataset = dataset.sample(10000, random_state=42)\n",
    "train_mask = np.random.rand(len(dataset)) < 0.8\n",
    "dataset_train = dataset[train_mask]\n",
    "dataset_test = dataset[~train_mask]\n",
    "\n",
    "f.close()\n",
    "\n",
    "print(len(dataset_train), len(dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним словарь токенов на основе train-выборки, чтобы далее можно было преобразовывать предложения в векторы. Дополнительно удобно ввести абстракцию токенизатора, чтобы не зудумываться о ручных выравниваниях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer(object):\n",
    "    def __init__(self, word2idx, tokenizer):\n",
    "        self.word2idx = word2idx\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, sentences, max_length=10, pad_to_max_length=False):\n",
    "        tokens = self.tokenizer.tokenize_sents(sentences)\n",
    "\n",
    "        if not pad_to_max_length:\n",
    "            max_length = min(max_length, max(map(len, tokens)))\n",
    "\n",
    "        tokens = [['[CLS]'] + s + ['[SEP]'] + ['[PAD]'] * (max_length - len(s)) \\\n",
    "                     if len(s) < max_length \\\n",
    "                     else ['[CLS]'] + s[:max_length] + ['[SEP]'] \\\n",
    "                  for s in tokens ]\n",
    "\n",
    "        ids = [[self.word2idx.get(w, self.word2idx['[UNK]']) for w in sent] for sent in tokens]\n",
    "\n",
    "        return torch.tensor(ids).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8061/8061 [00:00<00:00, 266201.75it/s]\n"
     ]
    }
   ],
   "source": [
    "word2idx = {'[PAD]': 0, '[UNK]': 1, '[CLS]': 3, '[SEP]': 4}\n",
    "idx2word = {0: '[PAD]', 1: '[UNK]', 3: '[CLS]', 4: '[SEP]'}\n",
    "tokenizer = RegexpTokenizer('[a-zA-Z]+|[^\\w\\s]|\\d+')\n",
    "\n",
    "for sent in tqdm(dataset_train.values[:, 1]):\n",
    "    for word in tokenizer.tokenize(sent):\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = word2idx.__len__()\n",
    "            idx2word[word2idx.__len__() - 1] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(word2idx, tokenizer)\n",
    "train_data_sent = tokenizer(dataset_train.values[:, 1])\n",
    "test_data_sent = tokenizer(dataset_test.values[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_pt = torch.utils.data.TensorDataset(\n",
    "    train_data_sent, train_data_sent)\n",
    "dataset_test_pt = torch.utils.data.TensorDataset(\n",
    "    test_data_sent, test_data_sent)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset_train_pt, batch_size=batch_size)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset_test_pt, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General training code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый обычный код обучения моделей за исключениесм нескольких специфичных изменений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sentence(sent):\n",
    "    sent = [idx2word[word] for word in sent]\n",
    "    return ' '.join(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_batch(model, batch_of_x, batch_of_y, optimizer, loss_function):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "\n",
    "    input, target = batch_of_x.to(device), batch_of_y.to(device)\n",
    "    output = model(src=input, target=target)\n",
    "\n",
    "    loss = loss_function(output.transpose(1, 2), target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_generator, model, loss_function, optimizer):\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    for it, (batch_of_x, batch_of_y) in enumerate(train_generator):\n",
    "        local_loss = train_on_batch(\n",
    "            model, batch_of_x, batch_of_y, optimizer, loss_function)\n",
    "\n",
    "        epoch_loss += local_loss * len(batch_of_x)\n",
    "        total += len(batch_of_x)\n",
    "\n",
    "    return epoch_loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataloader):\n",
    "    batch = next(iter(dataloader))\n",
    "    input, truth = batch[0].to(device), batch[1].to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(input, truth)\n",
    "        out, truth = torch.argmax(out.detach().cpu(), 2).numpy(), truth.detach().cpu().numpy()\n",
    "        result = ''\n",
    "        for i in range(min(out.shape[0], 8)):\n",
    "            result += 'Result: ' + print_sentence(out[i]) + ', Truth: ' + print_sentence(truth[i]) + '\\n'\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_of_train(model, test_dataloader, loss_function):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        epoch_loss = 0\n",
    "        total = 0\n",
    "        for batch_of_x, batch_of_y in test_dataloader:\n",
    "            input, target = batch_of_x.to(device), batch_of_y.to(device)\n",
    "            output = model(src=input, target=target)\n",
    "\n",
    "            loss = loss_function(output.transpose(1, 2), target).cpu().item()\n",
    "            epoch_loss += loss * len(batch_of_x)\n",
    "            total += len(batch_of_x)\n",
    "\n",
    "    return epoch_loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(count_of_epoch,\n",
    "            model,\n",
    "            train_dataloader,\n",
    "            test_dataloader,\n",
    "            loss_function,\n",
    "            optimizer, scheduler=None, writer=None):\n",
    "\n",
    "    iterations = range(count_of_epoch)\n",
    "    if writer is not None:\n",
    "        writer.add_scalar('Loss/test', quality_of_train(model, test_dataloader, loss_function), 0)\n",
    "        writer.add_text('text', test_model(model, test_dataloader), 0)\n",
    "\n",
    "    for it in iterations:\n",
    "        optima = optimizer\n",
    "\n",
    "        epoch_loss = train_epoch(\n",
    "            train_generator=train_dataloader,\n",
    "            model=model,\n",
    "            loss_function=loss_function,\n",
    "            optimizer=optima)\n",
    "\n",
    "        if writer is not None:\n",
    "            writer.add_scalar('Loss/train', epoch_loss, it + 1)\n",
    "            writer.add_scalar('Loss/test', quality_of_train(model, test_dataloader, loss_function), it + 1)\n",
    "            writer.add_text('text', test_model(model, test_dataloader), it + 1)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, dropout, bidirectional):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = torch.nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout, bidirectional=bidirectional)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim, n_layers, dropout, bidirectional):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = torch.nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout, bidirectional=bidirectional)\n",
    "        self.fc_out = torch.nn.Linear(hidden_dim * (2 if self.bidirectional else 1), output_dim)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(torch.nn.Module):\n",
    "    def __init__(self, vocabulary_size, emb_dim, hidden_dim, n_layers, dropout, bidirectional, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.encoder = Encoder(input_dim=vocabulary_size, emb_dim=emb_dim,\n",
    "                               hidden_dim=hidden_dim, n_layers=n_layers,\n",
    "                               dropout=dropout, bidirectional=bidirectional).to(device)\n",
    "        self.decoder = Decoder(output_dim=vocabulary_size, emb_dim=emb_dim,\n",
    "                               hidden_dim=hidden_dim, n_layers=n_layers,\n",
    "                               dropout=dropout, bidirectional=bidirectional).to(device)\n",
    "\n",
    "    def forward(self, src, target, teacher_forcing_ratio=0.5):\n",
    "        batch_size = target.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "        outputs = torch.zeros(target_len, batch_size, self.decoder.output_dim).to(self.device)\n",
    "        hidden, cell = self.encoder(src)\n",
    "        input = target[0, :]\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            input = target[t] if teacher_force else output.argmax(1)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним простой перебор параметров модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ParameterGrid({\n",
    "    'vocabulary_size': [len(word2idx)],\n",
    "    'emb_dim': [64, 128],\n",
    "    'hidden_dim': [128, 256],\n",
    "    'n_layers': [1, 2],\n",
    "    'dropout': [0.0, 0.2],\n",
    "    'bidirectional': [True, False]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': True, 'dropout': 0.0, 'emb_dim': 64, 'hidden_dim': 128, 'n_layers': 1, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/32 [00:59<30:56, 59.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': True, 'dropout': 0.0, 'emb_dim': 64, 'hidden_dim': 128, 'n_layers': 2, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 2/32 [02:18<35:29, 70.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': True, 'dropout': 0.0, 'emb_dim': 64, 'hidden_dim': 256, 'n_layers': 1, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 3/32 [03:42<37:02, 76.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': True, 'dropout': 0.0, 'emb_dim': 64, 'hidden_dim': 256, 'n_layers': 2, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 4/32 [05:32<41:56, 89.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': True, 'dropout': 0.0, 'emb_dim': 128, 'hidden_dim': 128, 'n_layers': 1, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 5/32 [06:39<36:45, 81.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': True, 'dropout': 0.0, 'emb_dim': 128, 'hidden_dim': 128, 'n_layers': 2, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 6/32 [07:57<34:49, 80.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': True, 'dropout': 0.0, 'emb_dim': 128, 'hidden_dim': 256, 'n_layers': 1, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 7/32 [09:19<33:48, 81.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': True, 'dropout': 0.0, 'emb_dim': 128, 'hidden_dim': 256, 'n_layers': 2, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 8/32 [11:13<36:37, 91.56s/it]/home/vokerlee/.local/lib/python3.11/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': True, 'dropout': 0.2, 'emb_dim': 64, 'hidden_dim': 128, 'n_layers': 1, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 9/32 [12:14<31:21, 81.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': True, 'dropout': 0.2, 'emb_dim': 64, 'hidden_dim': 128, 'n_layers': 2, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 10/32 [13:33<29:43, 81.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': True, 'dropout': 0.2, 'emb_dim': 64, 'hidden_dim': 256, 'n_layers': 1, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 11/32 [15:00<28:58, 82.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': True, 'dropout': 0.2, 'emb_dim': 64, 'hidden_dim': 256, 'n_layers': 2, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 12/32 [16:52<30:37, 91.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': True, 'dropout': 0.2, 'emb_dim': 128, 'hidden_dim': 128, 'n_layers': 1, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 13/32 [17:55<26:18, 83.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': True, 'dropout': 0.2, 'emb_dim': 128, 'hidden_dim': 128, 'n_layers': 2, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 14/32 [19:23<25:22, 84.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': True, 'dropout': 0.2, 'emb_dim': 128, 'hidden_dim': 256, 'n_layers': 1, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 15/32 [20:45<23:44, 83.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': True, 'dropout': 0.2, 'emb_dim': 128, 'hidden_dim': 256, 'n_layers': 2, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 16/32 [22:40<24:48, 93.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': False, 'dropout': 0.0, 'emb_dim': 64, 'hidden_dim': 128, 'n_layers': 1, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 17/32 [23:28<19:52, 79.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': False, 'dropout': 0.0, 'emb_dim': 64, 'hidden_dim': 128, 'n_layers': 2, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 18/32 [24:21<16:42, 71.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': False, 'dropout': 0.0, 'emb_dim': 64, 'hidden_dim': 256, 'n_layers': 1, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 19/32 [25:16<14:24, 66.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': False, 'dropout': 0.0, 'emb_dim': 64, 'hidden_dim': 256, 'n_layers': 2, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 20/32 [26:34<14:02, 70.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': False, 'dropout': 0.0, 'emb_dim': 128, 'hidden_dim': 128, 'n_layers': 1, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 21/32 [27:23<11:40, 63.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': False, 'dropout': 0.0, 'emb_dim': 128, 'hidden_dim': 128, 'n_layers': 2, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 22/32 [28:19<10:15, 61.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': False, 'dropout': 0.0, 'emb_dim': 128, 'hidden_dim': 256, 'n_layers': 1, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 23/32 [31:25<14:49, 98.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': False, 'dropout': 0.0, 'emb_dim': 128, 'hidden_dim': 256, 'n_layers': 2, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 24/32 [32:31<11:51, 88.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': False, 'dropout': 0.2, 'emb_dim': 64, 'hidden_dim': 128, 'n_layers': 1, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 25/32 [33:13<08:44, 74.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': False, 'dropout': 0.2, 'emb_dim': 64, 'hidden_dim': 128, 'n_layers': 2, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 26/32 [34:03<06:44, 67.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': False, 'dropout': 0.2, 'emb_dim': 64, 'hidden_dim': 256, 'n_layers': 1, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 27/32 [34:51<05:07, 61.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': False, 'dropout': 0.2, 'emb_dim': 64, 'hidden_dim': 256, 'n_layers': 2, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 28/32 [35:58<04:12, 63.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': False, 'dropout': 0.2, 'emb_dim': 128, 'hidden_dim': 128, 'n_layers': 1, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 29/32 [36:41<02:51, 57.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': False, 'dropout': 0.2, 'emb_dim': 128, 'hidden_dim': 128, 'n_layers': 2, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 30/32 [37:31<01:50, 55.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': False, 'dropout': 0.2, 'emb_dim': 128, 'hidden_dim': 256, 'n_layers': 1, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 31/32 [38:20<00:53, 53.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bidirectional': False, 'dropout': 0.2, 'emb_dim': 128, 'hidden_dim': 256, 'n_layers': 2, 'vocabulary_size': 18853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [39:28<00:00, 74.01s/it]\n"
     ]
    }
   ],
   "source": [
    "scores = dict()\n",
    "\n",
    "for item in tqdm(grid, leave=True):\n",
    "    print(str(item))\n",
    "\n",
    "    writer = SummaryWriter('experiment/' + str(item))\n",
    "\n",
    "    model = Autoencoder(**item, device=device)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_function = torch.nn.CrossEntropyLoss(ignore_index=word2idx['[PAD]'])\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "    trainer(count_of_epoch=4,\n",
    "            model=model,\n",
    "            train_dataloader=train_dataloader,\n",
    "            test_dataloader=test_dataloader,\n",
    "            loss_function=loss_function,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            writer=writer)\n",
    "\n",
    "    loss = quality_of_train(model, test_dataloader, loss_function)\n",
    "    scores[str(item)] = loss\n",
    "    writer.add_hparams(item, {'hparam/Test loss': loss})\n",
    "    writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель дала не очень хорошие результаты: loss равен около 6 и не сходится к нулю при проходе по эпохам. \n",
    "Предложения получаются не сильно осмысленные (не очень понятные или вообще не имеющие смысл).\n",
    "\n",
    "Перебор параметров практически ни на что не влияет, их влиянение не очень значительно: dropout немного улучшает сходимость, количество и число слоев не сильно влияют на модель.\n",
    "Увеличение размерности embedding'а уменьшает loss, но незначительно."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
