{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip experiment.zip -d .\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./experiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset & general parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_clusters_data(dataset_size, dim, n_clusters=5):\n",
    "    sigmas = []\n",
    "    mus = []\n",
    "    X = []\n",
    "\n",
    "    for _ in range(n_clusters):\n",
    "        center = np.random.uniform(-5, 5, dim) # center of gaussian\n",
    "        scales = np.random.uniform(1, 2, dim) # covariance\n",
    "\n",
    "        # Generate cloud of points\n",
    "        cluster = np.random.multivariate_normal(mean=center, cov=np.diag(scales), size=dataset_size)\n",
    "\n",
    "        sigmas.append(scales)\n",
    "        mus.append(center)\n",
    "        X.append(cluster)\n",
    "\n",
    "    X = np.stack(X).reshape(-1, dim)\n",
    "\n",
    "    return X, mus, sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = 5555\n",
    "n_clusters = 5\n",
    "dim = 2\n",
    "\n",
    "X, mus, sigmas = generate_clusters_data(dataset_size, dim, n_clusters)\n",
    "x, y = X.T\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.minorticks_on()\n",
    "plt.grid(which='minor', linestyle=':')\n",
    "plt.scatter(x, y, c='cyan', alpha=0.05)\n",
    "\n",
    "for i, mu in enumerate(mus):\n",
    "    plt.scatter(mu[0], mu[1], label=f\"cluster #{i + 1}\", marker='x')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.title('Synthetic data 2D data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_batch(model, x_batch, optimizer, loss_function):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output = model(x_batch.to(model.device))\n",
    "    loss = model.loss(*output)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    return loss.cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_generator, model, loss_function, optimizer, scheduler=None, callback=None):\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "\n",
    "    for it, batch_of_x in enumerate(train_generator):\n",
    "        batch_loss = train_on_batch(model, batch_of_x[0], optimizer, loss_function)\n",
    "\n",
    "        if callback is not None:\n",
    "            with torch.no_grad():\n",
    "                callback(model, batch_loss)\n",
    "\n",
    "        epoch_loss += batch_loss * len(batch_of_x)\n",
    "        total += len(batch_of_x)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    return epoch_loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(count_of_epoch,\n",
    "            batch_size,\n",
    "            dataset,\n",
    "            model,\n",
    "            loss_function,\n",
    "            optimizer,\n",
    "            lr=0.001,\n",
    "            callback=None):\n",
    "\n",
    "    optima = optimizer(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optima, gamma=0.95)\n",
    "\n",
    "    iterations = tqdm(range(count_of_epoch), desc='epoch')\n",
    "    iterations.set_postfix({'train epoch loss': np.nan})\n",
    "\n",
    "    for it in iterations:\n",
    "        batch_generator = tqdm(\n",
    "            torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True),\n",
    "            leave=False, total=len(dataset) // batch_size + (len(dataset) % batch_size > 0))\n",
    "\n",
    "        epoch_loss = train_epoch(train_generator=batch_generator,\n",
    "                    model=model,\n",
    "                    loss_function=loss_function,\n",
    "                    optimizer=optima,\n",
    "                    scheduler=scheduler,\n",
    "                    callback=callback)\n",
    "\n",
    "        iterations.set_postfix({'train epoch loss': epoch_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaVAE(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 latent_dim: int,\n",
    "                 n_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        hidden_dims = [6 * (2 ** i) for i in range(n_layers)]\n",
    "\n",
    "        self.fc_mu = torch.nn.Linear(hidden_dims[-1], latent_dim)\n",
    "        self.fc_var = torch.nn.Linear(hidden_dims[-1], latent_dim)\n",
    "\n",
    "        self.encoder_input = torch.nn.Linear(input_dim, hidden_dims[0])\n",
    "        self.decoder_input = torch.nn.Linear(latent_dim, hidden_dims[-1])\n",
    "\n",
    "        encoder_modules = []\n",
    "        decoder_modules = []\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            encoder_modules.append(\n",
    "                torch.nn.Sequential(\n",
    "                    torch.nn.Linear(hidden_dims[i], hidden_dims[i + 1]),\n",
    "                    torch.nn.BatchNorm1d(hidden_dims[i + 1]),\n",
    "                    torch.nn.LeakyReLU())\n",
    "            )\n",
    "\n",
    "        hidden_dims.reverse()\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            decoder_modules.append(\n",
    "                torch.nn.Sequential(\n",
    "                    torch.nn.Linear(hidden_dims[i], hidden_dims[i + 1]),\n",
    "                    torch.nn.BatchNorm1d(hidden_dims[i + 1]),\n",
    "                    torch.nn.LeakyReLU())\n",
    "            )\n",
    "\n",
    "        self.encoder = torch.nn.Sequential(self.encoder_input, *encoder_modules)\n",
    "        self.decoder = torch.nn.Sequential(self.decoder_input, *decoder_modules)\n",
    "\n",
    "        self.final_layer = torch.nn.Sequential(\n",
    "                            torch.nn.Linear(hidden_dims[-1], hidden_dims[-1]),\n",
    "                            torch.nn.BatchNorm1d(hidden_dims[-1]),\n",
    "                            torch.nn.LeakyReLU(),\n",
    "                            torch.nn.Linear(hidden_dims[-1], input_dim))\n",
    "\n",
    "    def encode(self, input):\n",
    "        \"\"\"\n",
    "        Generates distribution provided by input.\n",
    "        Args:\n",
    "            input: Tensor - the matrix of shape batch_size x input_dim.\n",
    "        Returns:\n",
    "            List[mu, log_var] - the normal distribution parameters.\n",
    "            mu: Tensor - the matrix of shape batch_size x latent_dim.\n",
    "            sigma: Tensor - the matrix of shape batch_size x latent_dim.\n",
    "        \"\"\"\n",
    "        result = self.encoder(input)\n",
    "        result = torch.flatten(result, start_dim=1)\n",
    "\n",
    "        # Split the result into mu and var components\n",
    "        # of the latent Gaussian distribution\n",
    "        mu = self.fc_mu(result)\n",
    "        log_var = self.fc_var(result)\n",
    "\n",
    "        return [mu, log_var]\n",
    "\n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        Maps the given latent codes onto the image space.\n",
    "        Args:\n",
    "            z: Tensor - the matrix of shape batch_size x latent_dim.\n",
    "        Returns:\n",
    "            Tensor - decoded sample.\n",
    "        \"\"\"\n",
    "        result = self.decoder(z)\n",
    "        result = self.final_layer(result)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def sample_z(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        Generates sample from normal distribution N(mu, var).\n",
    "        Args:\n",
    "            mu: Tensor - the matrix of shape batch_size x latent_dim.\n",
    "            sigma: Tensor - the matrix of shape batch_size x latent_dim.\n",
    "        Returns:\n",
    "            Tensor - the tensor of shape batch_size x latent_dim - samples from normal distribution in latent space.\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "\n",
    "    def forward(self, input, **kwargs):\n",
    "        mu, log_var = self.encode(input)\n",
    "        z = self.sample_z(mu, log_var)\n",
    "\n",
    "        return [self.decode(z), input, mu, log_var]\n",
    "\n",
    "    def loss(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes the VAE loss function.\n",
    "        \"\"\"\n",
    "        recons = args[0]\n",
    "        input = args[1]\n",
    "        mu = args[2]\n",
    "        log_var = args[3]\n",
    "\n",
    "        recons_loss = torch.nn.functional.mse_loss(recons, input)\n",
    "        kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0) # KL-divergention\n",
    "\n",
    "        loss = recons_loss + kld_loss\n",
    "        return loss # {'loss': loss, 'Reconstruction_Loss':recons_loss.detach(), 'KLD':-kld_loss.detach()}\n",
    "\n",
    "    def generate_samples(self, num_samples:int, **kwargs):\n",
    "        \"\"\"\n",
    "        Samples from the latent space and return the corresponding image space map.\n",
    "        Args:\n",
    "            num_samples: int - the number of samples, witch need to generate.\n",
    "        Returns:\n",
    "            Tensor - the matrix of shape num_samples x input_dim.\n",
    "        \"\"\"\n",
    "        z = torch.randn(num_samples, self.latent_dim)\n",
    "        z = z.to(self.device)\n",
    "\n",
    "        samples = self.decode(z)\n",
    "        return samples\n",
    "\n",
    "    def generate(self, x, **kwargs):\n",
    "        \"\"\"\n",
    "        Generate decoded sample after encoding.\n",
    "        Args:\n",
    "            x: Tensor - the matrix of shape batch_size x input_dim.\n",
    "        Returns:\n",
    "            Tensor - decoded sample after encoding of x.\n",
    "        \"\"\"\n",
    "        return self.forward(x)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard training tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class callback():\n",
    "    def __init__(self, writer, dataset_loader, loss_function, delimeter=100):\n",
    "        self.step = 0\n",
    "        self.writer = writer\n",
    "        self.delimeter = delimeter\n",
    "        self.loss_function = loss_function\n",
    "\n",
    "        self.dataset_loader = dataset_loader\n",
    "\n",
    "    def forward(self, model, loss):\n",
    "        self.step += 1\n",
    "        self.writer.add_scalar('LOSS/train', loss, self.step)\n",
    "\n",
    "    def __call__(self, model, loss):\n",
    "        return self.forward(model, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational autoencoder training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ParameterGrid({\n",
    "    'latent_dim': [2, 4, 8, 16, 32],\n",
    "    'n_layers': [4, 8, 12],\n",
    "})\n",
    "\n",
    "grid_input_dim = ParameterGrid({\n",
    "    'input_dim': [2, 8, 14],\n",
    "})\n",
    "\n",
    "for input_dim_item in grid_input_dim:\n",
    "    X, mus, sigmas = generate_clusters_data(dataset_size=20000, dim=input_dim_item['input_dim'])\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(np.array(X[:15000, :], dtype='float32')))\n",
    "    test_dataset = torch.utils.data.TensorDataset(torch.from_numpy(np.array(X[15000:, :], dtype='float32')))\n",
    "\n",
    "    for item in grid:\n",
    "        print(str(input_dim_item), str(item))\n",
    "\n",
    "        vae = VanillaVAE(\n",
    "            latent_dim=item['latent_dim'],\n",
    "            input_dim=input_dim_item['input_dim'],\n",
    "            n_layers=item['n_layers'])\n",
    "\n",
    "        vae.to(device)\n",
    "        vae.device=device\n",
    "\n",
    "        writer = SummaryWriter(log_dir=('experiment/' + str(str(input_dim_item)) + str(item)))\n",
    "        call = callback(writer, test_dataset, vae.loss, delimeter=100)\n",
    "\n",
    "        trainer(count_of_epoch=7,\n",
    "                batch_size=100,\n",
    "                dataset=train_dataset,\n",
    "                model=vae,\n",
    "                loss_function=vae.loss,\n",
    "                optimizer=optimizer,\n",
    "                lr=0.001,\n",
    "                callback=call)\n",
    "\n",
    "        if input_dim_item['input_dim'] == 2:\n",
    "            print(\"Picture\")\n",
    "            distr = vae.generate_samples(1000)\n",
    "            x, y = np.array(distr.detach().cpu()).T\n",
    "\n",
    "            plt.figure(figsize=(5, 4), dpi=100)\n",
    "            decoding = vae.generate(distr).detach().cpu()\n",
    "\n",
    "            plt.scatter(x, y, label='Initial data')\n",
    "            plt.scatter(decoding[:, 0], decoding[:, 1], label='Generated data')\n",
    "            plt.axis('equal')\n",
    "            plt.legend()\n",
    "            writer.add_figure('Samples', plt.gcf())\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
